# -*- coding: utf-8 -*-
# í›„ì²˜ë¦¬ ëª¨ë“ˆ. GPTë¡œ ìš”ì•½ ìƒì„±, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜, ì œëª©ê³¼ ë³¸ë¬¸ ìœ ì‚¬ë„ ì¸¡ì • ë° ë¶„ì„
#í˜„ì¬ëŠ” ìœ„ì˜ 3ê°€ì§€ ì‘ì—… ëª¨ë‘ GPTë¥¼ í™œìš©, ì¶”í›„ ê° taskë§ˆë‹¤ ì í•©í•œ AI modelì„ í™œìš©í•˜ë„ë¡ ë¦¬íŒ©í† ë§ ê°€ëŠ¥
import os
import json
import time
import math
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

def load_prompt(file_path):
    """ì§€ì •ëœ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œ"""
    with open(file_path, "r", encoding="utf-8") as file:
        return file.read()
    
def logprob_to_prob(logprob):
    """ë¡œê·¸ í™•ë¥ ì„ ì‹¤ì œ í™•ë¥ ë¡œ ë³€í™˜"""
    return math.exp(logprob)

def normalize_score(score, old_range=(1, 5), new_range=(0, 100)):
    """1~5 ì ìˆ˜ë¥¼ 0~100 ì ìœ¼ë¡œ ì •ê·œí™”"""
    old_min, old_max = old_range
    new_min, new_max = new_range
    normalized_score = ((score - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min

    return max(new_min, min(new_max, round(normalized_score, 2)))


def calculate_score(logprobs, token_range=(1, 5)):
    """ë¡œê·¸ í™•ë¥ ì„ ë°›ì•„ ì‹¤ì œ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³ , ì¢…í•© ì ìˆ˜ë¥¼ ê³„ì‚°"""
    score = 0
    token_probs = {str(i): 0 for i in range(token_range[0], token_range[1] + 1)}

    # logprobsì—ì„œ ìƒìœ„ í† í°ë“¤ì˜ í™•ë¥  ê³„ì‚°
    for logprob_item in logprobs:
        for top_logprob in logprob_item.top_logprobs:
            token_str = top_logprob.token
            if token_str in token_probs:
                prob = logprob_to_prob(top_logprob.logprob)
                if prob > token_probs[token_str]:
                    token_probs[token_str] = prob

    score = sum(int(token) * prob for token, prob in token_probs.items())
    
    return score, token_probs

def evaluate_score(title, content, prompt):
    """GEval ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ ê³„ì‚°"""
    # í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì²˜ë¦¬
    cur_prompt = prompt.replace("{{ì œëª©}}", title).replace("{{ë³¸ë¬¸}}", content)

    # GPT API í˜¸ì¶œ
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        max_tokens=5,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": cur_prompt
            }
        ],
        temperature=0,
        logprobs=True,
        top_logprobs=10,
    )

    logprobs_content = completion.choices[0].logprobs.content  # ê° í† í°ë³„ ë¡œê·¸ í™•ë¥  ë°ì´í„°
    score, token_probs = calculate_score(logprobs_content)

    return score, token_probs


def get_reasoning(title, content, hs_score, fs_score, prompt):
    """HS ë° FS ì ìˆ˜ì— ëŒ€í•œ íŒë‹¨ ê·¼ê±°ë¥¼ ì œê³µ"""
    cur_prompt = (prompt.replace("{{ì œëª©}}", title)
                         .replace("{{ë³¸ë¬¸}}", content)
                         .replace("{{hs}}", str(hs_score))
                         .replace("{{fs}}", str(fs_score)))

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": cur_prompt}
        ],
        max_tokens=500,
        temperature=0.2,
        top_p=0.9
    )

    return json.loads(response.choices[0].message.content)  


def analyze_news(news_data):
    """
    ë‹¨ì¼ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½ ìƒì„±, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜, HS/FS ì ìˆ˜ ê³„ì‚° í›„ ë°˜í™˜.
    """
    title = news_data["title"]
    content = news_data["content"]
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt_summary = load_prompt("./prompts/prompt_summary.txt")
    prompt_hs = load_prompt("./prompts/prompt_hs.txt")
    prompt_fs = load_prompt("./prompts/prompt_fs.txt")
    prompt_reason = load_prompt("./prompts/prompt_reason.txt")


    # ìš”ì•½ ìƒì„± ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    prompt = prompt_summary.replace("{{ì œëª©}}", title).replace("{{ë³¸ë¬¸}}", content)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        max_tokens=500,
        temperature=0.2,
        top_p=0.9
    )

        
    result = json.loads(response.choices[0].message.content)
        
    # ìš”ì•½ê³¼ ì¹´í…Œê³ ë¦¬ ê²°ê³¼ ì¶”ì¶œ
    news_data["summary"] = result["summary"]
    news_data["category"] = result["category"]
        
    # HS ì ìˆ˜ ê³„ì‚°
    hs_score, hs_token_probs = evaluate_score(title, content, prompt_hs)
    normalized_hs_score = normalize_score(hs_score)

    news_data["headline_score"] = normalized_hs_score
    news_data["headline_score_origin"] = hs_score
    news_data["headline_score_probs"] = hs_token_probs
        
    # FS ì ìˆ˜ ê³„ì‚°
    fs_score, fs_token_probs = evaluate_score(title, content, prompt_fs)
    normalized_fs_score = normalize_score(fs_score)

    news_data["fact_score"] = normalized_fs_score
    news_data["fact_score_origin"] = fs_score
    news_data["fact_score_probs"] = fs_token_probs  

    # íŒë‹¨ ê·¼ê±° ìš”ì²­
    reasoning_result = get_reasoning(title, content, normalized_hs_score, normalized_fs_score, prompt_reason)
    news_data["hs_reason"] = reasoning_result["hs_reason"]
    news_data["fs_reason"] = reasoning_result["fs_reason"]      

    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ: {news_data['title']}")

    return news_data


# ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ ì‹¤í–‰
if __name__ == "__main__":
    input_files = ["./news.json", "./enter.json", "./sport.json"]  # 3ê°œì˜ ì…ë ¥ íŒŒì¼
    output_file = "./analyzed_news.json"
    

    news_list = []

    # 3ê°œì˜ JSON íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ news_listì— ì¶”ê°€
    for file_path in input_files:
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                data = json.load(file)
                news_list.extend(data)  # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            print(f"ğŸ“¥ {file_path}ì—ì„œ {len(data)}ê°œì˜ ë‰´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        except FileNotFoundError:
            print(f"âš ï¸ {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        except json.JSONDecodeError:
            print(f"âŒ {file_path} íŒŒì¼ì˜ JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    analyzed_news = []

    start_time = time.time()  # ì‹œì‘ ì‹œê°„ ì¸¡ì •

    # ë‰´ìŠ¤ ë°ì´í„° í•˜ë‚˜ì”© ë¶„ì„
    for news in news_list:
        analyzed_news.append(analyze_news(news))

    elapsed_time = time.time() - start_time  # ê±¸ë¦° ì‹œê°„ ê³„ì‚°
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ: {len(analyzed_news)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"â± ë¶„ì„ì— ê±¸ë¦° ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

    # ë¶„ì„ ê²°ê³¼ ì €ì¥
    with open(output_file, "w", encoding="utf-8") as file:
        json.dump(analyzed_news, file, ensure_ascii=False, indent=4)
    
    print(f"ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

